# EASE-2020-Avatar-Fetch-and-Place

<img src="https://i.imgur.com/okAQ2ha.png" alt="drawing" width="500"/>


This neem include the actions of a human avatar performing a fetch-and-place task. The episode was recorded in a simulated physics-enabled environment. 
## Information

### About RoPHa
> (Robuste Wahrnehmungsfähigkeiten für Roboter zur Unterstützung älterer Nutzer im häuslichen Umfeld)
> The main research objective of RoPHa was to further develop the capabilities of service robots for assisitive tasks in the context of elderly care. The robot should learn how to perform everyday manipulation tasks safely and interactively. The developed functions were implemented on the service robot Care-O-bot 4 to enable it to prepare food, e.g. by cutting or sprinkling it, and guide it to the user's mouth. - https://www.ropha-projekt.de/

### Dataset
An avatar was used to perform a fetch-and place action.
The execution was performed in simulation.
We are utilizing simulation to enable faster learning since it allows us to generate a significant amount of data in a short period and safe environment.

Publications:

1. [Self-Specialization of General Robot Plans Based on Experience](https://ieeexplore.ieee.org/document/8763992)
   
2. [Learning Motion Parameterizations of Mobile Pick and Place Actions from Observing Humans in Virtual Environments](http://ras.papercept.net/images/temp/IROS/files/2587.pdf)
   
3. [The Robot Household Marathon Experiment](https://arxiv.org/abs/2011.09792)
   
4. [URoboSim -- An Episodic Simulation Framework for Prospective Reasoning in Robotic Agents](https://arxiv.org/abs/2012.04442)

### Acknowledgements
This work was supported  by the DFG CRC Everyday Activity Science and Engineering (EASE)(CRC #1320)and BMPF Project RoPHa.

## Accessing the data

Please refer to the NEEM-Hub section in [NEEM-Handbook](https://ease-crc.github.io/soma/owl/current/NEEM-Handbook.pdf) how you can download the data set.

## License
[MIT](https://choosealicense.com/licenses/mit/)
